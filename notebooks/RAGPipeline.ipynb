{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJ3FsjbIrUjg"
      },
      "outputs": [],
      "source": [
        "##"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#RAG Pipeline"
      ],
      "metadata": {
        "id": "Lk4YZbQ4r_Um"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU langchain-community faiss-cpu tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ql3WsCi-sCFY",
        "outputId": "094b7888-6aa5-4c22-c372-d47453a75a0b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.7/30.7 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.3/423.3 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  langchain-core langchain-huggingface langgraph langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "collapsed": true,
        "id": "IwXw4MmcsINZ",
        "outputId": "11f85328-dc3a-44a7-8347-048534c15450"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.3.51)\n",
            "Collecting langchain-huggingface\n",
            "  Downloading langchain_huggingface-0.1.2-py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.3.25-py3-none-any.whl.metadata (7.7 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (0.3.22)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (4.13.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (2.11.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.30.1)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (3.4.1)\n",
            "Requirement already satisfied: tokenizers>=0.19.1 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (0.21.1)\n",
            "Requirement already satisfied: transformers>=4.39.0 in /usr/local/lib/python3.11/dist-packages (from langchain-huggingface) (4.50.3)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.24-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt<0.2,>=0.1.1 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.61-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting xxhash<4.0.0,>=3.5.0 (from langgraph)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.16 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.17-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.29.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2025.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->langchain-huggingface) (4.67.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph)\n",
            "  Downloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (2.33.0)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core) (0.4.0)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.14.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (11.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (2.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (2024.11.6)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.39.0->langchain-huggingface) (0.5.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.69.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (4.9)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.23.0->langchain-huggingface) (2.3.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.6.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.16->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain-huggingface) (3.0.2)\n",
            "Downloading langchain_huggingface-0.1.2-py3-none-any.whl (21 kB)\n",
            "Downloading langgraph-0.3.25-py3-none-any.whl (142 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.4/142.4 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.1.2-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.17-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.24-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.1.8-py3-none-any.whl (25 kB)\n",
            "Downloading langgraph_sdk-0.1.61-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m99.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, xxhash, ormsgpack, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, langgraph-sdk, langgraph-checkpoint, google-ai-generativelanguage, langgraph-prebuilt, langchain-huggingface, langchain-google-genai, langgraph\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.17 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.17 langchain-google-genai-2.1.2 langchain-huggingface-0.1.2 langgraph-0.3.25 langgraph-checkpoint-2.0.24 langgraph-prebuilt-0.1.8 langgraph-sdk-0.1.61 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ormsgpack-1.9.1 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "4dd3da7d10114b95ba03d9465d5d2d24"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KAL-ie0jtEE1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6IGOZ85WvFbL",
        "outputId": "bb62e7a8-708c-458c-934a-d914731d0ec1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.4 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.17 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import START, END, StateGraph, MessagesState\n",
        "from langchain_core.messages import SystemMessage\n",
        "from langchain_core.tools import tool\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "from typing_extensions import List, TypedDict\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import pathlib\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "import faiss\n",
        "from langchain_community.vectorstores import FAISS\n"
      ],
      "metadata": {
        "id": "y39g_rEbsOjy"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gd5EeANtvoYk",
        "outputId": "6f7d327f-c9e0-4ae7-a909-ae90871eeb3f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "if \"GOOGLE_API_KEY\" not in os.environ:\n",
        "    os.environ[\"GOOGLE_API_KEY\"] = getpass.getpass(\"Enter your Google AI API key: \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7D7OGA1u4Qe",
        "outputId": "e83e8e9f-f3fd-4314-80c8-7313304e7b5e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your Google AI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_vector_db_from_local(file_name, embedding):\n",
        "    \"\"\"\n",
        "    Loads the vector DB from a local file.\n",
        "    \"\"\"\n",
        "    return FAISS.load_local(file_name, embedding, allow_dangerous_deserialization=True)\n",
        "\n",
        "def get_default_embeddings(model_name=\"sentence-transformers/all-mpnet-base-v2\"):\n",
        "    \"\"\"Return the default embedding model.\"\"\"\n",
        "    return HuggingFaceEmbeddings(model_name=model_name)\n",
        "\n",
        "\n",
        "def build_RAG_pipeline(llm, vector_store):\n",
        "    @tool(response_format=\"content_and_artifact\")\n",
        "    def retrieve(query: str):\n",
        "        \"\"\"Retrieve relevant information from the University of Connecticut knowledge base based on the user's query and provide context to help answer the question effectively.\"\"\"\n",
        "        retrieved_docs = search_vector_db(query, vector_store)\n",
        "        serialized = \"\\n\\n\".join(\n",
        "            (f\"Source: {doc[0].metadata}\\n\" f\"Content: {doc[0].page_content}\")\n",
        "            for doc in retrieved_docs\n",
        "        )\n",
        "        return serialized, retrieved_docs\n",
        "\n",
        "    def query_or_respond(state: MessagesState):\n",
        "        \"\"\"Generate tool call for retrieval or respond.\"\"\"\n",
        "        llm_with_tools = llm.bind_tools([retrieve])\n",
        "        system_message_content = \"\"\"You are an assistant designed to provide answers based on the University of Connecticut (UConn) knowledge base.\n",
        "        If a query is related to UConn and requires more context, call the tool with an appropriate query to fetch relevant documents from the knowledge base.\n",
        "\n",
        "        - Ensure the query is specific and clearly related to the subject matter to retrieve the most relevant documents.\n",
        "        - If you feel the query could be rewritten to fetch more relevant content, feel free to adjust or rephrase it to better align with the knowledge base.\n",
        "         \"\"\"\n",
        "        prompt = [SystemMessage(system_message_content)] + state['messages']\n",
        "        print(f\"Input message ------{prompt}\")\n",
        "        response = llm_with_tools.invoke(prompt)\n",
        "        return {\"messages\": [response]}\n",
        "\n",
        "    def generate(state: MessagesState):\n",
        "        \"\"\"Generate answer.\"\"\"\n",
        "        # Get generated ToolMessages\n",
        "        recent_tool_messages = []\n",
        "        for message in reversed(state[\"messages\"]):\n",
        "            if message.type == \"tool\":\n",
        "                recent_tool_messages.append(message)\n",
        "            else:\n",
        "                break\n",
        "        tool_messages = recent_tool_messages[::-1]\n",
        "\n",
        "        # Format into prompt\n",
        "        docs_content = \"\\n\\n\".join(doc.content for doc in tool_messages)\n",
        "\n",
        "        system_message_content = (\n",
        "            \"\"\"\"You are an assistant designed to answer questions related to the University of Connecticut (UConn) knowledge base. When responding,\n",
        "            utilize the provided context to generate accurate answers. If you are uncertain about the answer,\n",
        "            acknowledge that you don’t know. For questions that inquire \"How,\" provide a detailed, step-by-step explanation. Whenever necessary,\n",
        "             include metadata with the URL of the original source site to ensure proper attribution.\"\"\"\n",
        "            \"\\n\\n\"\n",
        "            f\"{docs_content}\"\n",
        "        )\n",
        "        conversation_messages = [\n",
        "            message\n",
        "            for message in state[\"messages\"]\n",
        "            if message.type in (\"human\", \"system\")\n",
        "               or (message.type == \"ai\" and not message.tool_calls)\n",
        "        ]\n",
        "        prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
        "\n",
        "        # Run\n",
        "        response = llm.invoke(prompt)\n",
        "        return {\"messages\": [response]}\n",
        "\n",
        "    graph_builder = StateGraph(MessagesState)\n",
        "    tools = ToolNode([retrieve])\n",
        "    graph_builder.add_node(query_or_respond)\n",
        "    graph_builder.add_node(tools)\n",
        "    graph_builder.add_node(generate)\n",
        "\n",
        "    graph_builder.set_entry_point(\"query_or_respond\")\n",
        "    # graph_builder.add_edge(\"query_or_respond\", \"tools\")\n",
        "    graph_builder.add_conditional_edges(\n",
        "        \"query_or_respond\",\n",
        "        tools_condition,\n",
        "        {END: END, \"tools\": \"tools\"},\n",
        "    )\n",
        "    graph_builder.add_edge(\"tools\", \"generate\")\n",
        "    graph_builder.add_edge(\"generate\", END)\n",
        "    graph = graph_builder.compile()\n",
        "\n",
        "    return graph"
      ],
      "metadata": {
        "id": "VEz2IXzmspZy"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def search_vector_db(query, vector_store, k=5, filter=None):\n",
        "    \"\"\"\n",
        "    Perform a search in the vector database by querying for the most similar documents.\n",
        "\n",
        "    Parameters:\n",
        "    - query (str): The search query string for which similar documents are being sought.\n",
        "    - vector_store (FAISS): The FAISS vector store that contains the document vectors to search against.\n",
        "    - k (int, optional): The number of nearest neighbors (documents) to return. Default is 5.\n",
        "    - filter (dict, optional): A filter to apply to the search (e.g., metadata filtering). Default is None.\n",
        "\n",
        "    Returns:\n",
        "    - list: A list of the top `k` most similar documents, along with their similarity scores.\n",
        "    \"\"\"\n",
        "    # Perform the similarity search in the vector store using the provided query and filter (if any)\n",
        "    documents = vector_store.similarity_search_with_score(query, k=k, filter=filter)\n",
        "\n",
        "    return documents"
      ],
      "metadata": {
        "id": "_A_SQ8zjwwUB"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_dir = pathlib.Path(\"/content/drive/MyDrive/Colab Notebooks/Capstone\")\n",
        "vector_db_location = data_dir / \"faiss_index\"\n",
        "embedding = get_default_embeddings()\n",
        "\n",
        "# Load the vector store from disk\n",
        "vector_store = load_vector_db_from_local(vector_db_location, embedding)\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-2.0-flash-001\",\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2,\n",
        "    # other params...\n",
        ")\n"
      ],
      "metadata": {
        "id": "JPHRKHbStpan"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graph = build_RAG_pipeline(llm, vector_store)"
      ],
      "metadata": {
        "id": "D6r_i3BdviSW"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_message = \"Tell me more about two-factor authentication in netid\"\n",
        "\n",
        "for step in graph.stream(\n",
        "    {\"messages\": [{\"role\": \"user\", \"content\": input_message}]},\n",
        "    stream_mode=\"values\",\n",
        "):\n",
        "    step[\"messages\"][-1].pretty_print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "934Ux8rjwFeJ",
        "outputId": "67be4482-470a-4d5a-8bb3-24cfc7cf8c69"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "================================\u001b[1m Human Message \u001b[0m=================================\n",
            "\n",
            "Tell me more about two-factor authentication in netid\n",
            "Input message ------[SystemMessage(content='You are an assistant designed to provide answers based on the University of Connecticut (UConn) knowledge base.\\n        If a query is related to UConn and requires more context, call the tool with an appropriate query to fetch relevant documents from the knowledge base. \\n         \\n        - Ensure the query is specific and clearly related to the subject matter to retrieve the most relevant documents.\\n        - If you feel the query could be rewritten to fetch more relevant content, feel free to adjust or rephrase it to better align with the knowledge base.\\n         ', additional_kwargs={}, response_metadata={}), HumanMessage(content='Tell me more about two-factor authentication in netid', additional_kwargs={}, response_metadata={}, id='964bf34b-1ab8-4d49-b650-3239b1af93cc')]\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "Tool Calls:\n",
            "  retrieve (363bd44c-eaa6-4f38-b16c-7f5968aef5b5)\n",
            " Call ID: 363bd44c-eaa6-4f38-b16c-7f5968aef5b5\n",
            "  Args:\n",
            "    query: two-factor authentication netid uconn\n",
            "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
            "Name: retrieve\n",
            "\n",
            "Source: {'creationdate': '2025-03-02T00:56:24+00:00', 'source': '/content/drive/MyDrive/Colab Notebooks/Capstone/Data/IT-NetId_18.pdf', 'total_pages': 6, 'title': 'Logging in with 2FA - Information Technology - UConn Knowledge Base', 'keywords': '', 'file_name': 'IT-NetId_18.pdf', 'url': 'https://kb.uconn.edu/space/IKB/10785228242'}\n",
            "Content: Logging in with 2FA\n",
            "Last updated 24 January, 2025 • 3 min read\n",
            "When two-factor authentication (2FA) is required for login, account holders will\n",
            "receive a prompt from Duo after they enter their NetID credentials. You will\n",
            "authenticate the request with a push, call, or code on the device you added to the\n",
            "2FA service. \n",
            "The simplest way to use 2FA at UConn while traveling is to download and\n",
            "set up the Duo Mobile app for authentication. Duo Mobile works\n",
            "both with and without internet access on your second device and is ITS’s\n",
            "recommended second factor authentication method for all situations.\n",
            "Authentication Methods \n",
            "Authenticating via Push Notification (Duo Mobile App)\n",
            "\n",
            "Authenticating Using a Passcode\n",
            "\n",
            "\f\n",
            "\fAuthenticating via Phone Call\n",
            "\n",
            "Authenticating Using a Text Message\n",
            "\n",
            "\fSometimes a phone's or carrier's security settings will change, which may\n",
            "prevent or hamper the receipt of the push notification. If you are no longer\n",
            "\n",
            "Source: {'creationdate': '2025-03-02T01:08:59+00:00', 'source': '/content/drive/MyDrive/Colab Notebooks/Capstone/Data/IT-Network_6.pdf', 'total_pages': 2, 'title': 'What is the UConn Remote Desktop Gateway? - Information Technology - UConn Knowledge Base', 'keywords': '', 'file_name': 'IT-Network_6.pdf', 'url': 'https://kb.uconn.edu/space/IKB/10845094703'}\n",
            "Content: time to put in their NetID and password. The second time, the NetID needs to be\n",
            "entered as \"uconn\\NetID,\" and the user must accept the Duo push or phone call.\n",
            "For UCHC individuals: Those who do not have a Duo account in Storrs will need to\n",
            "use VPN to connect to a Storrs PC, or use Anyware to connect to a remote PC on\n",
            "the UConn Domain (Storrs Network).\n",
            "For any questions or concerns, please contact the UConn Technology Support\n",
            "Center.\n",
            "Related Articles\n",
            "\fLoad more\n",
            "Platform Authenticators for the 2FA Service\n",
            "24 Jan, 2025\n",
            "\n",
            "Switching from Text to the Duo Mobile App\n",
            "8 May, 2024\n",
            "\n",
            "Student Guide to UConn Technology\n",
            "9 days ago\n",
            "\n",
            "USB Security Keys for the 2FA Service\n",
            "24 Jan, 2025\n",
            "\n",
            "Set Up Cisco AnyConnect VPN\n",
            "10 Jan, 2025\n",
            "\n",
            "What is the UConn Remote Desktop Gateway?\n",
            "8 Aug, 2023\n",
            "\n",
            "Home Internet Performance\n",
            "2 Jan, 2024\n",
            "\n",
            "Setting up a Mobile Phone for 2FA\n",
            "9 days ago\n",
            "\n",
            "Logging in with 2FA\n",
            "24 Jan, 2025\n",
            "\n",
            "Setting Up 2FA on a Device\n",
            "2 Nov, 2022\n",
            "\n",
            "\n",
            "Source: {'creationdate': '2025-03-02T00:58:22+00:00', 'source': '/content/drive/MyDrive/Colab Notebooks/Capstone/Data/IT-NetId_36.pdf', 'total_pages': 2, 'title': 'Synchronizing Your NetID Password (Password Test) - Information Technology - UConn Knowledge Base', 'keywords': '', 'file_name': 'IT-NetId_36.pdf', 'url': 'https://kb.uconn.edu/space/IKB/10749249644'}\n",
            "Content: Synchronizing Your NetID Password (Password\n",
            "Test)\n",
            "Last updated 21 October, 2024 • 1 min read\n",
            "If you are unable to log in to UConn systems or lose access to UConn-Secure Wi-\n",
            "Fi, one of the first troubleshooting steps is to make sure your NetID password is\n",
            "synchronized with our systems. You check this by performing a password test.\n",
            "NetID passwords can become unsynchronized for various reasons; for\n",
            "example, age can be a factor. Old or outdated passwords can result in\n",
            "users losing access to various University applications (most commonly Wi-\n",
            "Fi and Active Directory).\n",
            "Running a NetID Password Test \n",
            "1. Navigate to the NetID website.\n",
            "2. Sign in with your NetID and NetID password.\n",
            "3. Click on My NetID in the blue ribbon.  \n",
            "4. Select Password Test from the drop-down menu.\n",
            "5. Enter your login information. \n",
            "All three tests should pass and show a \"Synchronized\" message in the box next to\n",
            "it. \n",
            "If one of the test results is red (i.e., Unsynchronized), see Changing Your\n",
            "NetID Password.\n",
            "\n",
            "Source: {'creationdate': '2025-03-02T00:55:05+00:00', 'source': '/content/drive/MyDrive/Colab Notebooks/Capstone/Data/IT-NetId_1.pdf', 'total_pages': 1, 'title': 'Accounts, NetID, and Duo - Information Technology - UConn Knowledge Base', 'keywords': '', 'file_name': 'IT-NetId_1.pdf', 'url': 'https://kb.uconn.edu/space/IKB/10724476730'}\n",
            "Content: Accounts, NetID, and Duo\n",
            "Last updated 9 November, 2023 • 1 min read\n",
            "All faculty, staff, students, and affiliates receive a NetID, a unique UConn identifier,\n",
            "when they join the University. A NetID is the cornerstone for your digital identity and\n",
            "is necessary to authenticate into most online services at UConn, including Core-CT.\n",
            "The University provides you with tools to protect your NetID (i.e., manage\n",
            "passwords and two-factor authentication) and modify how your name is published.\n",
            "\n",
            "Source: {'creationdate': '2025-03-02T00:55:51+00:00', 'source': '/content/drive/MyDrive/Colab Notebooks/Capstone/Data/IT-NetId_11.pdf', 'total_pages': 2, 'title': 'Duo Two-Factor Authentication - Information Technology - UConn Knowledge Base', 'keywords': '', 'file_name': 'IT-NetId_11.pdf', 'url': 'https://kb.uconn.edu/space/IKB/10726900331'}\n",
            "Content: Duo Two-Factor Authentication\n",
            "Last updated 19 December, 2024 • 2 min read\n",
            "Two-factor authentication (2FA), powered by Duo Security, is required for faculty,\n",
            "staff, special payroll, student employees, and students. 2FA enhances data security\n",
            "by requiring two forms of identification to gain access to an online resource.\n",
            "What is two factor authentication? \n",
            "Two-factor authentication (2FA) protects the login process and prevents\n",
            "unauthorized access to your data. 2FA requires two forms of identification before\n",
            "access is provided. At UConn, you first log in with your NetID (the “first factor”) and\n",
            "then verify that it is you logging in by answering a prompt on your device (the\n",
            "“second factor”). This way, even if your credentials are stolen, you can block access\n",
            "by denying this second factor.\n",
            "Duo Mobile is an authentication app that works with Duo Security’s two-\n",
            "factor authentication service. Once installed from your app store, the app\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Two-factor authentication (2FA), powered by Duo Security, is required for faculty, staff, special payroll, student employees, and students at UConn. 2FA enhances data security by requiring two forms of identification to gain access to an online resource. With 2FA, you first log in with your NetID (the “first factor”) and then verify that it is you logging in by answering a prompt on your device (the “second factor”). Even if your credentials are stolen, you can block access by denying this second factor. After entering your NetID credentials, you will receive a prompt from Duo, which you can authenticate with a push, call, or code on the device you added to the 2FA service. The simplest way to use 2FA at UConn while traveling is to download and set up the Duo Mobile app for authentication. Duo Mobile works both with and without internet access on your second device and is ITS’s recommended second factor authentication method for all situations.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "m4gni1AUwOzG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}